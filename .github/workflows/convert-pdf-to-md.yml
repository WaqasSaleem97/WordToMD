name: Convert PDF to Markdown with OCR (fallbacks)

on:
  push:
    paths:
      - '**/*.pdf'

permissions:
  contents: write

jobs:
  convert-pdf:
    runs-on: ubuntu-latest
    env:
      OCR_LANG: "eng" # change if you need other language(s), e.g. "eng+spa"
      DEBUG_KEEP_INTERMEDIATES: "false" # set to "true" to keep intermediate files for debugging

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Install tools (pandoc, poppler-utils, tesseract, ghostscript, qpdf, pip)
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc poppler-utils tesseract-ocr ghostscript qpdf python3-pip
          python3 -m pip install --upgrade ocrmypdf

      - name: Convert PDFs to Markdown (OCR fallback + image extraction)
        run: |
          set -euo pipefail
          mkdir -p converted
          find . -type f -name "*.pdf" -print0 | while IFS= read -r -d '' file; do
            if [ ! -f "$file" ]; then
              echo "File not found: $file"
              continue
            fi

            filename=$(basename "$file" .pdf)
            echo "=== Processing $file -> converted/${filename}.md ==="
            mkdir -p "converted/${filename}_media"

            (
              cd converted

              # 1) Try quick text extraction with pdftotext (keep logs visible)
              echo "Running pdftotext for ${filename}..."
              pdftotext -layout "../$file" "${filename}.txt" || true

              # 2) If no text, run OCR with ocrmypdf
              if [ ! -s "${filename}.txt" ]; then
                echo "No text from pdftotext; running ocrmypdf (OCR) on $file"
                # --skip-text avoids OCR when text already exists; fine because we only get here when text is missing
                ocrmypdf --skip-text --rotate-pages --deskew -l "${OCR_LANG}" "../$file" "${filename}_ocr.pdf" || true
                if [ -f "${filename}_ocr.pdf" ]; then
                  echo "Extracting text from OCR'd PDF..."
                  pdftotext -layout "${filename}_ocr.pdf" "${filename}.txt" || true
                fi
              fi

              # 3) If still no text, rasterize pages and run tesseract page-by-page
              if [ ! -s "${filename}.txt" ]; then
                echo "OCR produced no text; rasterizing pages and running tesseract on images"
                # pdftoppm will create files like ${filename}_page-1.png
                pdftoppm -png -r 300 "../$file" "${filename}_page" || true
                if ls "${filename}_page-"*.png >/dev/null 2>&1; then
                  rm -f "${filename}_ocr_pages.txt" || true
                  for img in "${filename}_page-"*.png; do
                    outbase="${img%.*}"
                    echo "Running tesseract on ${img} -> ${outbase}.txt"
                    # tesseract syntax: tesseract input.png outputbase -l LANG
                    tesseract "$img" "$outbase" -l "${OCR_LANG}" quiet || true
                    txtfile="${outbase}.txt"
                    if [ -f "${txtfile}" ]; then
                      cat "${txtfile}" >> "${filename}_ocr_pages.txt"
                      echo -e "\n\n" >> "${filename}_ocr_pages.txt"
                    fi
                  done
                  if [ -s "${filename}_ocr_pages.txt" ]; then
                    mv "${filename}_ocr_pages.txt" "${filename}.txt"
                  fi
                else
                  echo "No page images created by pdftoppm for ${filename}"
                fi
              fi

              # 4) Extract embedded images regardless (pdfimages)
              echo "Extracting embedded images with pdfimages (if any)"
              pdfimages -all "../$file" "${filename}_media/image" || true

              # 5) Create Markdown from text; if no text, put a note
              if [ -s "${filename}.txt" ]; then
                echo "Converting text to Markdown with pandoc..."
                pandoc "${filename}.txt" -f markdown -t gfm -o "${filename}.md" || cp "${filename}.txt" "${filename}.md"
              else
                echo "<!-- No text extracted from ${file} -->" > "${filename}.md"
              fi

              # 6) Append links for extracted images so they appear in the markdown
              if ls "${filename}_media"/* >/dev/null 2>&1; then
                echo -e "\n\n---\n\n### Extracted images\n" >> "${filename}.md"
                for img in "${filename}_media"/*; do
                  imgname=$(basename "$img")
                  # Add a relative image link
                  echo "![](${filename}_media/${imgname})" >> "${filename}.md"
                done
              fi

              # 7) Clean Pandoc inline image attributes like {width="..."} (handles multi-line)
              if [ -f "${filename}.md" ]; then
                perl -0777 -pe 's/!\[([^\]]*)\]\(([^)]+)\)\{[^}]+\}/![\1](\2)/gs' -i "${filename}.md" || true
              fi

              # 8) Remove intermediates unless debug is enabled
              if [ "${DEBUG_KEEP_INTERMEDIATES}" != "true" ]; then
                rm -f "${filename}.txt" "${filename}_ocr.pdf" "${filename}_ocr_pages.txt" "${filename}_page-"*.png "${filename}_page-"*.png.txt || true
              else
                echo "DEBUG_KEEP_INTERMEDIATES=true â€” keeping intermediate files for inspection"
              fi
            )

            echo "=== Finished ${filename} ==="
          done

      - name: Commit and push converted files and media
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
        run: |
          git config --global user.name 'github-actions'
          git config --global user.email 'github-actions@github.com'
          git add converted/
          git commit -m "Auto-converted PDFs to Markdown with OCR and images" || echo "No changes to commit"
          git push https://${GH_PAT}@github.com/${{ github.repository }} HEAD:${{ github.ref_name }}
